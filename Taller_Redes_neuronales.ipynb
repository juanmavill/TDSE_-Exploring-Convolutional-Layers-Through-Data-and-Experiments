{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731d07f5",
   "metadata": {},
   "source": [
    "# Taller de Redes Neuronales Convolucionales\n",
    "\n",
    "\n",
    "\n",
    "## ¿Por qué CIFAR-10 es ideal para redes convolucionales?\n",
    "\n",
    "Las imágenes tienen características que las convoluciones aprovechan muy bien:\n",
    "\n",
    "- **Estructura espacial**: Los píxeles cercanos están relacionados entre sí (un ojo está cerca de otro ojo, las ruedas están debajo del coche, etc.)\n",
    "- **Patrones locales**: Bordes, texturas y formas son características que aparecen en regiones pequeñas de la imagen\n",
    "- **Invarianza a la traslación**: Un gato sigue siendo un gato esté en la esquina o en el centro de la imagen\n",
    "- **Tamaño manejable**: El dataset cabe en memoria sin problemas, perfecto para experimentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f0771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b674125e",
   "metadata": {},
   "source": [
    "## 1. Cargar el Dataset CIFAR-10\n",
    "\n",
    "CIFAR-10 es un dataset clásico en visión por computadora. Contiene 60,000 imágenes a color de 32×32 píxeles distribuidas en 10 categorías:\n",
    "\n",
    "**Las 10 clases son:** avión, automóvil, pájaro, gato, ciervo, perro, rana, caballo, barco y camión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c583b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Cargamos el dataset (se descarga automáticamente si es la primera vez)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Nombres de las clases en español\n",
    "nombres_clases = ['avión', 'automóvil', 'pájaro', 'gato', 'ciervo', \n",
    "                  'perro', 'rana', 'caballo', 'barco', 'camión']\n",
    "\n",
    "print(\"Forma del conjunto de entrenamiento:\", x_train.shape)\n",
    "print(\"Forma de las etiquetas de entrenamiento:\", y_train.shape)\n",
    "print(\"Forma del conjunto de prueba:\", x_test.shape)\n",
    "print(\"Forma de las etiquetas de prueba:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb00536",
   "metadata": {},
   "source": [
    "## 2. Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Antes de entrenar cualquier modelo, es fundamental entender lo que se esta trabajando. Vamos a explorar la estructura del dataset, ver ejemplos de cada clase y analizar la distribución de los datos.\n",
    "\n",
    "### 2.1 Estructura general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435131ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos las características principales del dataset\n",
    "print(\"=\" * 50)\n",
    "print(\"ESTRUCTURA DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Imágenes de entrenamiento: {x_train.shape[0]:,}\")\n",
    "print(f\"Imágenes de prueba: {x_test.shape[0]:,}\")\n",
    "print(f\"Dimensiones de cada imagen: {x_train.shape[1]} × {x_train.shape[2]} píxeles\")\n",
    "print(f\"Canales de color: {x_train.shape[3]} (RGB)\")\n",
    "print(f\"Rango de valores de píxel: [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Tipo de dato: {x_train.dtype}\")\n",
    "print(f\"Total de características por imagen: {32 * 32 * 3:,} valores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd7eb5e",
   "metadata": {},
   "source": [
    "### 2.2 Distribución de clases\n",
    "\n",
    "Un aspecto importante es verificar si el dataset está balanceado. Si una clase tiene muchas más muestras que otra, el modelo podría sesgarse hacia la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cuántas imágenes hay de cada clase\n",
    "valores_unicos, conteos = np.unique(y_train, return_counts=True)\n",
    "distribucion = dict(zip([nombres_clases[i] for i in valores_unicos], conteos))\n",
    "\n",
    "print(\"Distribución de clases en el conjunto de entrenamiento:\\n\")\n",
    "for clase, cantidad in distribucion.items():\n",
    "    porcentaje = cantidad / len(y_train) * 100\n",
    "    print(f\"  {clase:12s}: {cantidad:,} imágenes ({porcentaje:.1f}%)\")\n",
    "\n",
    "# Visualizamos la distribución\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar([nombres_clases[i] for i in valores_unicos], conteos, color='steelblue')\n",
    "plt.title('Distribución de Clases en CIFAR-10')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Cantidad de imágenes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ El dataset está perfectamente balanceado: 5,000 imágenes por clase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee5b4e",
   "metadata": {},
   "source": [
    "### 2.3 Visualización de ejemplos\n",
    "\n",
    "Nada mejor que ver las imágenes para entender con qué estamos trabajando. Primero veamos un ejemplo de cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos una imagen de cada clase\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx_clase in range(10):\n",
    "    # Buscamos la primera imagen de esta clase\n",
    "    idx_imagen = np.where(y_train.flatten() == idx_clase)[0][0]\n",
    "    axes[idx_clase].imshow(x_train[idx_imagen])\n",
    "    axes[idx_clase].set_title(nombres_clases[idx_clase])\n",
    "    axes[idx_clase].axis('off')\n",
    "\n",
    "plt.suptitle('Un ejemplo de cada clase', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58184f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos más variedad: 5 ejemplos de cada clase\n",
    "fig, axes = plt.subplots(10, 5, figsize=(10, 18))\n",
    "\n",
    "for idx_clase in range(10):\n",
    "    # Obtenemos los índices de las primeras 5 imágenes de esta clase\n",
    "    indices = np.where(y_train.flatten() == idx_clase)[0][:5]\n",
    "    for j, idx in enumerate(indices):\n",
    "        axes[idx_clase, j].imshow(x_train[idx])\n",
    "        if j == 0:\n",
    "            axes[idx_clase, j].set_ylabel(nombres_clases[idx_clase], fontsize=10)\n",
    "        axes[idx_clase, j].axis('off')\n",
    "\n",
    "plt.suptitle('Variedad de ejemplos por clase', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observa cómo hay mucha variación dentro de cada clase:\")\n",
    "print(\"- Diferentes fondos, ángulos, iluminación y tamaños\")\n",
    "print(\"- Esto hace que la clasificación sea un reto interesante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dd3ec",
   "metadata": {},
   "source": [
    "### 2.4 Distribución de valores de píxel\n",
    "\n",
    "También es útil ver cómo se distribuyen los valores de intensidad en cada canal de color (Rojo, Verde, Azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97231868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de cada canal de color\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "canales = ['Rojo', 'Verde', 'Azul']\n",
    "colores = ['red', 'green', 'blue']\n",
    "\n",
    "for i, (nombre, color) in enumerate(zip(canales, colores)):\n",
    "    axes[i].hist(x_train[:, :, :, i].flatten(), bins=50, color=color, alpha=0.7)\n",
    "    axes[i].set_title(f'Canal {nombre}')\n",
    "    axes[i].set_xlabel('Valor del píxel')\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.suptitle('Distribución de valores de píxel por canal (antes de normalizar)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0194d4c",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Datos\n",
    "\n",
    "Antes de entrenar el modelo, necesitamos preparar los datos. Esto incluye dos pasos fundamentales:\n",
    "\n",
    "### 3.1 Normalización de píxeles\n",
    "\n",
    "Las imágenes originales tienen valores entre 0 y 255. Las redes neuronales funcionan mejor cuando los valores de entrada son pequeños (entre 0 y 1). La solución es simple: dividimos cada valor por 255.\n",
    "\n",
    "$$\n",
    "x_{normalizado} = \\frac{x_{original}}{255}\n",
    "$$\n",
    "\n",
    "**¿Por qué normalizamos?**\n",
    "- Los gradientes se mantienen en rangos razonables\n",
    "- El entrenamiento es más estable y rápido\n",
    "- Evitamos problemas numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d537502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los valores de píxel al rango [0, 1]\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Rango de píxeles después de normalizar: [{x_train_norm.min()}, {x_train_norm.max()}]\")\n",
    "print(f\"Tipo de dato: {x_train_norm.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3c068",
   "metadata": {},
   "source": [
    "### 3.2 Codificación One-Hot de las etiquetas\n",
    "\n",
    "Las etiquetas originales son números enteros del 0 al 9. Sin embargo, nuestra red neuronal usará una capa softmax que produce 10 probabilidades (una por clase). Para calcular la pérdida, necesitamos que las etiquetas también sean vectores de 10 elementos.\n",
    "\n",
    "**Ejemplo de codificación one-hot:**\n",
    "\n",
    "| Etiqueta original | Clase | Vector one-hot |\n",
    "|-------------------|-------|----------------|\n",
    "| 3 | gato | [0, 0, 0, **1**, 0, 0, 0, 0, 0, 0] |\n",
    "| 0 | avión | [**1**, 0, 0, 0, 0, 0, 0, 0, 0, 0] |\n",
    "| 7 | caballo | [0, 0, 0, 0, 0, 0, 0, **1**, 0, 0] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convertimos las etiquetas a formato one-hot\n",
    "y_train_oh = to_categorical(y_train, num_classes=10)\n",
    "y_test_oh = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(f\"Forma original de etiquetas: {y_train.shape}\")\n",
    "print(f\"Forma después de one-hot: {y_train_oh.shape}\")\n",
    "\n",
    "# Veamos un ejemplo concreto\n",
    "etiqueta_original = y_train[0][0]\n",
    "print(f\"\\nEjemplo:\")\n",
    "print(f\"  Etiqueta original: {etiqueta_original} ({nombres_clases[etiqueta_original]})\")\n",
    "print(f\"  Vector one-hot: {y_train_oh[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3bab24",
   "metadata": {},
   "source": [
    "### 3.3 Verificación del preprocesamiento\n",
    "\n",
    "Siempre es buena idea verificar que todo esté correcto antes de continuar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60861c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos algunas imágenes normalizadas para verificar que se ven bien\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train_norm[i])\n",
    "    axes[i].set_title(nombres_clases[y_train[i][0]])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Imágenes normalizadas (valores entre 0 y 1)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"✓ PREPROCESAMIENTO COMPLETADO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Datos de entrenamiento: {x_train_norm.shape}\")\n",
    "print(f\"  Etiquetas de entrenamiento: {y_train_oh.shape}\")\n",
    "print(f\"  Datos de prueba: {x_test_norm.shape}\")\n",
    "print(f\"  Etiquetas de prueba: {y_test_oh.shape}\")\n",
    "print(\"\\n¡Los datos están listos para entrenar!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
